{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7beeee1-8ecb-4367-aece-f20a4a6e87fc",
   "metadata": {},
   "source": [
    "*A/B Test Analysis: Search Ranking System*\r\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5863b57-b5e0-4070-ab02-9d30adc117ea",
   "metadata": {},
   "source": [
    "Goal\r\n",
    "-----\r\n",
    "Prepare the dataset and analyze an experiment comparing a new search ranking (variant)\r\n",
    "against the current version (control). Decide whether to \"go full on\" (roll out) based on:\r\n",
    "\r\n",
    "1) Primary metric: conversion (booking happened or not)\r\n",
    "2) Guardrail metric: time_to_booking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233f730-5d6e-4c8b-9c72-9f619a99c71c",
   "metadata": {},
   "source": [
    "Predefined parameters\n",
    "---------------------\n",
    "- Confidence level: 90%\n",
    "- Significance level: alpha = 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ee5f0-636c-4576-a685-bde894e87881",
   "metadata": {},
   "source": [
    "Steps\n",
    "-----\n",
    "1) Load data and join sessions (behavior) to users (experiment groups) -> sessions_x_users\n",
    "2) Create the binary primary metric: conversion = 1 if booking_timestamp is present, else 0\n",
    "3) Run a Sample Ratio Mismatch (SRM) check to confirm balanced assignment\n",
    "4) Test experiment effect:\n",
    "   - Primary (binary): two-sided Z-test for proportions\n",
    "   - Guardrail (continuous): two-sided t-test of means\n",
    "5) Compute relative effect sizes for both metrics:\n",
    "   effect_size = mean(variant) / mean(control) - 1\n",
    "6) Make decision:\n",
    "   - \"full on\" (yes) if:\n",
    "       a) primary p-value < alpha AND effect_size_primary > 0\n",
    "       b) guardrail p-value > alpha OR effect_size_guardrail <= 0\n",
    "     Else \"pull back\" (no).\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7dc49bd-4065-40d7-902e-aadf6f3aa120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare, ttest_ind\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5125d2e5-3671-4d0a-a7cc-b49f0a3cdf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER: relative effect size\n",
    "def estimate_effect_size(df: pd.DataFrame, metric: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate relative effect size\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): data with experiment_group ('control', 'variant') and metric columns.\n",
    "    - metric (str): name of the metric column\n",
    "\n",
    "    Returns:\n",
    "    - effect_size (float): average treatment effect (effect size)\n",
    "    \"\"\"\n",
    "    avg_metric_per_group = df.groupby('experiment_group')[metric].mean()\n",
    "    effect_size = avg_metric_per_group['variant'] / avg_metric_per_group['control'] - 1\n",
    "    return effect_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59eb5ac9-961a-4fb8-9da6-0dbe12a1826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED PARAMETERS\n",
    "confidence_level = 0.90               # 90% confidence\n",
    "alpha = 1 - confidence_level          # significance level (0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecd73f44-c579-4bba-953c-daee24c60529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "users = pd.read_csv('users_data.csv')       # contains user_id and experiment_group (control/variant)\n",
    "sessions = pd.read_csv('sessions_data.csv') # contains user_id, booking_timestamp, time_to_booking, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5f00275-d3f0-48f1-b45a-1a1d48272a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== USERS: shape / columns / dtypes ===\n",
      "(10000, 2)\n",
      "['user_id', 'experiment_group']\n",
      "user_id             object\n",
      "experiment_group    object\n",
      "dtype: object \n",
      "\n",
      "            user_id experiment_group\n",
      "0  TcCIMrtQ75wHGXVj          variant\n",
      "1  GUGVzto9KGqeX3dc          variant\n",
      "2  uNcuV49WhPJ8C0MH          variant \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== USERS: shape / columns / dtypes ===\")\n",
    "print(users.shape)\n",
    "print(list(users.columns))\n",
    "print(users.dtypes, \"\\n\")\n",
    "print(users.head(3), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55b99ff0-a64f-4142-a5cb-7408fdd2c176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SESSIONS: shape / columns / dtypes ===\n",
      "(16981, 5)\n",
      "['session_id', 'user_id', 'session_start_timestamp', 'booking_timestamp', 'time_to_booking']\n",
      "session_id                  object\n",
      "user_id                     object\n",
      "session_start_timestamp     object\n",
      "booking_timestamp           object\n",
      "time_to_booking            float64\n",
      "dtype: object \n",
      "\n",
      "         session_id           user_id        session_start_timestamp  \\\n",
      "0  CP0lbAGnb5UNi3Ut  TcCIMrtQ75wHGXVj  2025-01-26 20:02:39.177358627   \n",
      "1  UQAjrPYair63L1p8  TcCIMrtQ75wHGXVj  2025-01-20 16:12:51.536912203   \n",
      "2  9zQrAPxV5oi2SzSa  TcCIMrtQ75wHGXVj  2025-01-28 03:46:40.839362144   \n",
      "\n",
      "  booking_timestamp  time_to_booking  \n",
      "0               NaN              NaN  \n",
      "1               NaN              NaN  \n",
      "2               NaN              NaN  \n"
     ]
    }
   ],
   "source": [
    "print(\"=== SESSIONS: shape / columns / dtypes ===\")\n",
    "print(sessions.shape)\n",
    "print(list(sessions.columns))\n",
    "print(sessions.dtypes, \"\\n\")\n",
    "print(sessions.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebfbfbab-0375-496e-b8a3-8d4a1ee3ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN DATA\n",
    "sessions_x_users = sessions.merge(users, on='user_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a203505-548f-4a97-97d6-f3e7d73dc524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIMARY METRIC: conversion\n",
    "# Binary conversion flag: 1 if booking occurred, 0 otherwise\n",
    "sessions_x_users['conversion'] = sessions_x_users['booking_timestamp'].notnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "761e6fc3-9023-4f89-8893-6820a95b10af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SANITY CHECK: Sample Ratio Mismatch (SRM) ===\n",
      "Assignments -> control: 7,630 | variant: 7,653 | total: 15,283\n",
      "SRM chi-square p-value: 0.8524\n",
      "No SRM detected at alpha = 0.10.\n"
     ]
    }
   ],
   "source": [
    "# 1) SANITY CHECK: SAMPLE RATIO MISMATCH TEST\n",
    "# Count assignments in each arm (ensure the index order is control, variant for clarity)\n",
    "groups_count = sessions_x_users['experiment_group'].value_counts().reindex(['control','variant']).fillna(0).astype(int)\n",
    "n = groups_count.sum()\n",
    "\n",
    "# Expected counts under perfect 50/50 split\n",
    "expected = [n/2, n/2]\n",
    "\n",
    "srm_chi2_stat, srm_chi2_pval = chisquare(f_obs=groups_count.values, f_exp=expected)\n",
    "srm_chi2_pval = round(float(srm_chi2_pval), 4)\n",
    "\n",
    "print(\"=== SANITY CHECK: Sample Ratio Mismatch (SRM) ===\")\n",
    "print(f\"Assignments -> control: {groups_count['control']:,} | variant: {groups_count['variant']:,} | total: {n:,}\")\n",
    "print(f\"SRM chi-square p-value: {srm_chi2_pval:.4f}\")\n",
    "if srm_chi2_pval < alpha:\n",
    "    print(\"Possible SRM (p < alpha). Interpret downstream results with caution.\")\n",
    "else:\n",
    "    print(\"No SRM detected at alpha = 0.10.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec643e6-3470-458a-bdec-04f88182fddc",
   "metadata": {},
   "source": [
    "The sample sizes between control (7,630 users) and variant (7,653 users) are nearly identical, with only a 0.15% imbalance. The chi-square test produced a p-value of 0.8524, well above the 0.10 significance threshold. This indicates there is no evidence of a Sample Ratio Mismatch (SRM). Randomization across experiment groups appears balanced, and we can confidently proceed with the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acb5f882-91cd-476d-9c90-74a5999c7248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRIMARY METRIC: Conversion ===\n",
      "Control conversion rate: 15.9240%\n",
      "Variant conversion rate: 18.1889%\n",
      "Z-test p-value: 0.0002\n",
      "Relative effect size: 14.2200% (=(variant/ control) - 1)\n"
     ]
    }
   ],
   "source": [
    "# 2) EFFECT ON PRIMARY METRIC\n",
    "# Compute success counts and sample sizes for each group\n",
    "success_counts = sessions_x_users.groupby('experiment_group', observed=True)['conversion'].sum().reindex(['control','variant'])\n",
    "sample_sizes   = sessions_x_users['experiment_group'].value_counts().reindex(['control','variant'])\n",
    "\n",
    "# Run Z-test for proportions (binary conversion metric)\n",
    "zstat_primary, pval_primary = proportions_ztest(count=success_counts.values,\n",
    "                                                nobs=sample_sizes.values,\n",
    "                                                alternative='two-sided')\n",
    "pval_primary = round(float(pval_primary), 4)\n",
    "\n",
    "# Estimate effect size for the conversion metric\n",
    "effect_size_primary = round(estimate_effect_size(sessions_x_users, 'conversion'), 4)\n",
    "\n",
    "print(\"\\n=== PRIMARY METRIC: Conversion ===\")\n",
    "print(f\"Control conversion rate: {success_counts['control'] / sample_sizes['control']:.4%}\")\n",
    "print(f\"Variant conversion rate: {success_counts['variant'] / sample_sizes['variant']:.4%}\")\n",
    "print(f\"Z-test p-value: {pval_primary:.4f}\")\n",
    "print(f\"Relative effect size: {effect_size_primary:.4%} (=(variant/ control) - 1)\")\n",
    "\n",
    "success_counts = sessions_x_users.groupby('experiment_group')['conversion'].sum().loc[['control', 'variant']]\n",
    "sample_sizes = sessions_x_users['experiment_group'].value_counts().loc[['control', 'variant']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcbde0e-0a57-4c3f-a02c-4be4f3cb511c",
   "metadata": {},
   "source": [
    "The control group converted at a rate of 15.92%, while the variant achieved an 18.19% conversion rate. This is an absolute increase of ~2.26 percentage points and a relative lift of 14.22%. The Z-test p-value (0.0002) is far below the 0.10 threshold, meaning the observed improvement is statistically significant. This provides strong evidence that the new search ranking system positively impacts booking conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0737270-672f-4b70-a95e-d5936cb59da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GUARDRAIL METRIC: Time to Booking ===\n",
      "Control mean time_to_booking: 15.0124\n",
      "Variant mean time_to_booking: 14.8940\n",
      "T-test p-value: 0.5365\n",
      "Relative effect size: -0.7900% (negative is good here, i.e., faster)\n"
     ]
    }
   ],
   "source": [
    "# 3) EFFECT ON GUARDRAIL METRIC\n",
    "# Note: Lower time_to_booking is better. Our decision rule treats:\n",
    "# - Non-significant change as OK, OR\n",
    "# - A significant change that *decreases* time_to_booking (i.e., variant <= control) as OK.\n",
    "# T-test on time to booking for control vs variant\n",
    "\n",
    "control_ttb = sessions_x_users.loc[sessions_x_users['experiment_group']=='control', 'time_to_booking'].dropna()\n",
    "variant_ttb = sessions_x_users.loc[sessions_x_users['experiment_group']=='variant', 'time_to_booking'].dropna()\n",
    "\n",
    "tstat_guardrail, pval_guardrail = ttest_ind(variant_ttb, control_ttb, equal_var=False, alternative='two-sided')\n",
    "pval_guardrail = round(float(pval_guardrail), 4)\n",
    "\n",
    "# Estimate effect size for the guardrail metric\n",
    "effect_size_guardrail = round(estimate_effect_size(sessions_x_users, 'time_to_booking'), 4)\n",
    "\n",
    "print(\"\\n=== GUARDRAIL METRIC: Time to Booking ===\")\n",
    "print(f\"Control mean time_to_booking: {control_ttb.mean():.4f}\")\n",
    "print(f\"Variant mean time_to_booking: {variant_ttb.mean():.4f}\")\n",
    "print(f\"T-test p-value: {pval_guardrail:.4f}\")\n",
    "print(f\"Relative effect size: {effect_size_guardrail:.4%} (negative is good here, i.e., faster)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52259e4-dfa0-4e91-8e7e-0061b3e3fc99",
   "metadata": {},
   "source": [
    "The mean time to booking in the control group was 15.01, while in the variant it dropped slightly to 14.89. The relative effect size of -0.79% suggests bookings occurred marginally faster in the variant. However, the p-value of 0.5365 is much larger than 0.10, indicating this difference is not statistically significant. Importantly, the guardrail metric was not harmedâ€”there was no evidence of slower bookings in the variant group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7803a69f-f0ca-4edc-bb45-433a460cbb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) DECISION LOGIC\n",
    "# Primary metric must be statistically significant and show positive effect (increase)\n",
    "criteria_full_on_primary = (pval_primary < alpha) & (effect_size_primary > 0)\n",
    "\n",
    "# Guardrail must either be statistically insignificant or whow positive effect (decrease)\n",
    "criteria_full_on_guardrail = (pval_guardrail > alpha) | (effect_size_guardrail <= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d705a65-4a8e-415e-a18f-f39094ba7c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision: GO FULL ON\n",
      "Reason: Primary metric improved significantly (p < 0.10 & effect > 0) AND guardrail not harmed\n",
      "        (either no significant change or the time_to_booking decreased).\n"
     ]
    }
   ],
   "source": [
    "if criteria_full_on_primary and criteria_full_on_guardrail:\n",
    "    decision_full_on = 'yes'\n",
    "    print(\"\\nDecision: GO FULL ON\")\n",
    "    print(\"Reason: Primary metric improved significantly (p < 0.10 & effect > 0) AND guardrail not harmed\")\n",
    "    print(\"        (either no significant change or the time_to_booking decreased).\")\n",
    "else:\n",
    "    decision_full_on = 'no'\n",
    "    print(\"\\nDecision: PULL BACK\")\n",
    "    print(\"Reason: Either the primary effect was not significantly positive, or the guardrail was harmed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391fdce-ceea-4f34-ab64-77647a75c568",
   "metadata": {},
   "source": [
    "Based on the decision criteria, the experiment supports rolling out the new search ranking system. The primary metric (conversion) showed a statistically significant and positive improvement. Meanwhile, the guardrail metric (time to booking) did not show any statistically significant harm and even suggested a slight speed-up. Together, these results justify moving forward with a full launch of the variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7be9c529-81d4-4366-9b91-458a65f7f770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY OUTPUTS ===\n",
      "srm_chi2_pval         = 0.8524\n",
      "pval_primary          = 0.0002\n",
      "effect_size_primary   = 0.1422\n",
      "pval_guardrail        = 0.5365\n",
      "effect_size_guardrail = -0.0079\n",
      "decision_full_on      = yes\n"
     ]
    }
   ],
   "source": [
    "# 5) SAVE KEY OUTPUTS (as variables)\n",
    "\n",
    "# Already set: srm_chi2_pval, pval_primary, pval_guardrail, effect_size_primary, effect_size_guardrail, decision_full_on\n",
    "print(\"\\n=== SUMMARY OUTPUTS ===\")\n",
    "print(f\"srm_chi2_pval         = {srm_chi2_pval}\")\n",
    "print(f\"pval_primary          = {pval_primary}\")\n",
    "print(f\"effect_size_primary   = {effect_size_primary}\")\n",
    "print(f\"pval_guardrail        = {pval_guardrail}\")\n",
    "print(f\"effect_size_guardrail = {effect_size_guardrail}\")\n",
    "print(f\"decision_full_on      = {decision_full_on}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d640e9ef-be9f-47de-9630-d8594e74314f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
