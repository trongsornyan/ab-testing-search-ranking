{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7beeee1-8ecb-4367-aece-f20a4a6e87fc",
   "metadata": {},
   "source": [
    "*A/B Test Analysis: Search Ranking System*\r\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5863b57-b5e0-4070-ab02-9d30adc117ea",
   "metadata": {},
   "source": [
    "Goal\r\n",
    "-----\r\n",
    "Prepare the dataset and analyze an experiment comparing a new search ranking (variant)\r\n",
    "against the current version (control). Decide whether to \"go full on\" (roll out) based on:\r\n",
    "\r\n",
    "1) Primary metric: conversion (booking happened or not)\r\n",
    "2) Guardrail metric: time_to_booking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233f730-5d6e-4c8b-9c72-9f619a99c71c",
   "metadata": {},
   "source": [
    "Predefined parameters\n",
    "---------------------\n",
    "- Confidence level: 90%\n",
    "- Significance level: alpha = 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ee5f0-636c-4576-a685-bde894e87881",
   "metadata": {},
   "source": [
    "Steps\n",
    "-----\n",
    "1) Load data and join sessions (behavior) to users (experiment groups) -> sessions_x_users\n",
    "2) Create the binary primary metric: conversion = 1 if booking_timestamp is present, else 0\n",
    "3) Run a Sample Ratio Mismatch (SRM) check to confirm balanced assignment\n",
    "4) Test experiment effect:\n",
    "   - Primary (binary): two-sided Z-test for proportions\n",
    "   - Guardrail (continuous): two-sided t-test of means\n",
    "5) Compute relative effect sizes for both metrics:\n",
    "   effect_size = mean(variant) / mean(control) - 1\n",
    "6) Make decision:\n",
    "   - \"full on\" (yes) if:\n",
    "       a) primary p-value < alpha AND effect_size_primary > 0\n",
    "       b) guardrail p-value > alpha OR effect_size_guardrail <= 0\n",
    "     Else \"pull back\" (no).\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7dc49bd-4065-40d7-902e-aadf6f3aa120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare, ttest_ind\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5125d2e5-3671-4d0a-a7cc-b49f0a3cdf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER: relative effect size\n",
    "def estimate_effect_size(df: pd.DataFrame, metric: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate relative effect size\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): data with experiment_group ('control', 'variant') and metric columns.\n",
    "    - metric (str): name of the metric column\n",
    "\n",
    "    Returns:\n",
    "    - effect_size (float): average treatment effect (effect size)\n",
    "    \"\"\"\n",
    "    avg_metric_per_group = df.groupby('experiment_group')[metric].mean()\n",
    "    effect_size = avg_metric_per_group['variant'] / avg_metric_per_group['control'] - 1\n",
    "    return effect_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59eb5ac9-961a-4fb8-9da6-0dbe12a1826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED PARAMETERS\n",
    "confidence_level = 0.90               # 90% confidence\n",
    "alpha = 1 - confidence_level          # significance level (0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecd73f44-c579-4bba-953c-daee24c60529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "users = pd.read_csv('users_data.csv')       # contains user_id and experiment_group (control/variant)\n",
    "sessions = pd.read_csv('sessions_data.csv') # contains user_id, booking_timestamp, time_to_booking, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5f00275-d3f0-48f1-b45a-1a1d48272a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== USERS: shape / columns / dtypes ===\n",
      "(10000, 2)\n",
      "['user_id', 'experiment_group']\n",
      "user_id             object\n",
      "experiment_group    object\n",
      "dtype: object \n",
      "\n",
      "            user_id experiment_group\n",
      "0  TcCIMrtQ75wHGXVj          variant\n",
      "1  GUGVzto9KGqeX3dc          variant\n",
      "2  uNcuV49WhPJ8C0MH          variant \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== USERS: shape / columns / dtypes ===\")\n",
    "print(users.shape)\n",
    "print(list(users.columns))\n",
    "print(users.dtypes, \"\\n\")\n",
    "print(users.head(3), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55b99ff0-a64f-4142-a5cb-7408fdd2c176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SESSIONS: shape / columns / dtypes ===\n",
      "(16981, 5)\n",
      "['session_id', 'user_id', 'session_start_timestamp', 'booking_timestamp', 'time_to_booking']\n",
      "session_id                  object\n",
      "user_id                     object\n",
      "session_start_timestamp     object\n",
      "booking_timestamp           object\n",
      "time_to_booking            float64\n",
      "dtype: object \n",
      "\n",
      "         session_id           user_id        session_start_timestamp  \\\n",
      "0  CP0lbAGnb5UNi3Ut  TcCIMrtQ75wHGXVj  2025-01-26 20:02:39.177358627   \n",
      "1  UQAjrPYair63L1p8  TcCIMrtQ75wHGXVj  2025-01-20 16:12:51.536912203   \n",
      "2  9zQrAPxV5oi2SzSa  TcCIMrtQ75wHGXVj  2025-01-28 03:46:40.839362144   \n",
      "\n",
      "  booking_timestamp  time_to_booking  \n",
      "0               NaN              NaN  \n",
      "1               NaN              NaN  \n",
      "2               NaN              NaN  \n"
     ]
    }
   ],
   "source": [
    "print(\"=== SESSIONS: shape / columns / dtypes ===\")\n",
    "print(sessions.shape)\n",
    "print(list(sessions.columns))\n",
    "print(sessions.dtypes, \"\\n\")\n",
    "print(sessions.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebfbfbab-0375-496e-b8a3-8d4a1ee3ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN DATA\n",
    "sessions_x_users = sessions.merge(users, on='user_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a203505-548f-4a97-97d6-f3e7d73dc524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIMARY METRIC: conversion\n",
    "# Binary conversion flag: 1 if booking occurred, 0 otherwise\n",
    "sessions_x_users['conversion'] = sessions_x_users['booking_timestamp'].notnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "761e6fc3-9023-4f89-8893-6820a95b10af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SANITY CHECK: Sample Ratio Mismatch (SRM) ===\n",
      "Assignments -> control: 7,630 | variant: 7,653 | total: 15,283\n",
      "SRM chi-square p-value: 0.8524\n",
      "No SRM detected at alpha = 0.10.\n"
     ]
    }
   ],
   "source": [
    "# 1) SANITY CHECK: SAMPLE RATIO MISMATCH TEST\n",
    "# Count assignments in each arm (ensure the index order is control, variant for clarity)\n",
    "groups_count = sessions_x_users['experiment_group'].value_counts().reindex(['control','variant']).fillna(0).astype(int)\n",
    "n = groups_count.sum()\n",
    "\n",
    "# Expected counts under perfect 50/50 split\n",
    "expected = [n/2, n/2]\n",
    "\n",
    "srm_chi2_stat, srm_chi2_pval = chisquare(f_obs=groups_count.values, f_exp=expected)\n",
    "srm_chi2_pval = round(float(srm_chi2_pval), 4)\n",
    "\n",
    "print(\"=== SANITY CHECK: Sample Ratio Mismatch (SRM) ===\")\n",
    "print(f\"Assignments -> control: {groups_count['control']:,} | variant: {groups_count['variant']:,} | total: {n:,}\")\n",
    "print(f\"SRM chi-square p-value: {srm_chi2_pval:.4f}\")\n",
    "if srm_chi2_pval < alpha:\n",
    "    print(\"Possible SRM (p < alpha). Interpret downstream results with caution.\")\n",
    "else:\n",
    "    print(\"No SRM detected at alpha = 0.10.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec643e6-3470-458a-bdec-04f88182fddc",
   "metadata": {},
   "source": [
    "The sample sizes between control (7,630 users) and variant (7,653 users) are nearly identical, with only a 0.15% imbalance. The chi-square test produced a p-value of 0.8524, well above the 0.10 significance threshold. This indicates there is no evidence of a Sample Ratio Mismatch (SRM). Randomization across experiment groups appears balanced, and we can confidently proceed with the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acb5f882-91cd-476d-9c90-74a5999c7248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRIMARY METRIC: Conversion ===\n",
      "Control conversion rate: 15.9240%\n",
      "Variant conversion rate: 18.1889%\n",
      "Z-test p-value: 0.0002\n",
      "Relative effect size: 14.2200% (=(variant/ control) - 1)\n"
     ]
    }
   ],
   "source": [
    "# 2) EFFECT ON PRIMARY METRIC\n",
    "# Compute success counts and sample sizes for each group\n",
    "success_counts = sessions_x_users.groupby('experiment_group', observed=True)['conversion'].sum().reindex(['control','variant'])\n",
    "sample_sizes   = sessions_x_users['experiment_group'].value_counts().reindex(['control','variant'])\n",
    "\n",
    "# Run Z-test for proportions (binary conversion metric)\n",
    "zstat_primary, pval_primary = proportions_ztest(count=success_counts.values,\n",
    "                                                nobs=sample_sizes.values,\n",
    "                                                alternative='two-sided')\n",
    "pval_primary = round(float(pval_primary), 4)\n",
    "\n",
    "# Estimate effect size for the conversion metric\n",
    "effect_size_primary = round(estimate_effect_size(sessions_x_users, 'conversion'), 4)\n",
    "\n",
    "print(\"\\n=== PRIMARY METRIC: Conversion ===\")\n",
    "print(f\"Control conversion rate: {success_counts['control'] / sample_sizes['control']:.4%}\")\n",
    "print(f\"Variant conversion rate: {success_counts['variant'] / sample_sizes['variant']:.4%}\")\n",
    "print(f\"Z-test p-value: {pval_primary:.4f}\")\n",
    "print(f\"Relative effect size: {effect_size_primary:.4%} (=(variant/ control) - 1)\")\n",
    "\n",
    "success_counts = sessions_x_users.groupby('experiment_group')['conversion'].sum().loc[['control', 'variant']]\n",
    "sample_sizes = sessions_x_users['experiment_group'].value_counts().loc[['control', 'variant']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcbde0e-0a57-4c3f-a02c-4be4f3cb511c",
   "metadata": {},
   "source": [
    "The control group converted at a rate of 15.92%, while the variant achieved an 18.19% conversion rate. This is an absolute increase of ~2.26 percentage points and a relative lift of 14.22%. The Z-test p-value (0.0002) is far below the 0.10 threshold, meaning the observed improvement is statistically significant. This provides strong evidence that the new search ranking system positively impacts booking conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0737270-672f-4b70-a95e-d5936cb59da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GUARDRAIL METRIC: Time to Booking ===\n",
      "Control mean time_to_booking: 15.0124\n",
      "Variant mean time_to_booking: 14.8940\n",
      "T-test p-value: 0.5365\n",
      "Relative effect size: -0.7900% (negative is good here, i.e., faster)\n"
     ]
    }
   ],
   "source": [
    "# 3) EFFECT ON GUARDRAIL METRIC\n",
    "# Note: Lower time_to_booking is better. Our decision rule treats:\n",
    "# - Non-significant change as OK, OR\n",
    "# - A significant change that *decreases* time_to_booking (i.e., variant <= control) as OK.\n",
    "# T-test on time to booking for control vs variant\n",
    "\n",
    "control_ttb = sessions_x_users.loc[sessions_x_users['experiment_group']=='control', 'time_to_booking'].dropna()\n",
    "variant_ttb = sessions_x_users.loc[sessions_x_users['experiment_group']=='variant', 'time_to_booking'].dropna()\n",
    "\n",
    "tstat_guardrail, pval_guardrail = ttest_ind(variant_ttb, control_ttb, equal_var=False, alternative='two-sided')\n",
    "pval_guardrail = round(float(pval_guardrail), 4)\n",
    "\n",
    "# Estimate effect size for the guardrail metric\n",
    "effect_size_guardrail = round(estimate_effect_size(sessions_x_users, 'time_to_booking'), 4)\n",
    "\n",
    "print(\"\\n=== GUARDRAIL METRIC: Time to Booking ===\")\n",
    "print(f\"Control mean time_to_booking: {control_ttb.mean():.4f}\")\n",
    "print(f\"Variant mean time_to_booking: {variant_ttb.mean():.4f}\")\n",
    "print(f\"T-test p-value: {pval_guardrail:.4f}\")\n",
    "print(f\"Relative effect size: {effect_size_guardrail:.4%} (negative is good here, i.e., faster)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52259e4-dfa0-4e91-8e7e-0061b3e3fc99",
   "metadata": {},
   "source": [
    "The mean time to booking in the control group was 15.01, while in the variant it dropped slightly to 14.89. The relative effect size of -0.79% suggests bookings occurred marginally faster in the variant. However, the p-value of 0.5365 is much larger than 0.10, indicating this difference is not statistically significant. Importantly, the guardrail metric was not harmed—there was no evidence of slower bookings in the variant group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7803a69f-f0ca-4edc-bb45-433a460cbb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) DECISION LOGIC\n",
    "# Primary metric must be statistically significant and show positive effect (increase)\n",
    "criteria_full_on_primary = (pval_primary < alpha) & (effect_size_primary > 0)\n",
    "\n",
    "# Guardrail must either be statistically insignificant or whow positive effect (decrease)\n",
    "criteria_full_on_guardrail = (pval_guardrail > alpha) | (effect_size_guardrail <= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d705a65-4a8e-415e-a18f-f39094ba7c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision: GO FULL ON\n",
      "Reason: Primary metric improved significantly (p < 0.10 & effect > 0) AND guardrail not harmed\n",
      "        (either no significant change or the time_to_booking decreased).\n"
     ]
    }
   ],
   "source": [
    "if criteria_full_on_primary and criteria_full_on_guardrail:\n",
    "    decision_full_on = 'yes'\n",
    "    print(\"\\nDecision: GO FULL ON\")\n",
    "    print(\"Reason: Primary metric improved significantly (p < 0.10 & effect > 0) AND guardrail not harmed\")\n",
    "    print(\"        (either no significant change or the time_to_booking decreased).\")\n",
    "else:\n",
    "    decision_full_on = 'no'\n",
    "    print(\"\\nDecision: PULL BACK\")\n",
    "    print(\"Reason: Either the primary effect was not significantly positive, or the guardrail was harmed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391fdce-ceea-4f34-ab64-77647a75c568",
   "metadata": {},
   "source": [
    "Based on the decision criteria, the experiment supports rolling out the new search ranking system. The primary metric (conversion) showed a statistically significant and positive improvement. Meanwhile, the guardrail metric (time to booking) did not show any statistically significant harm and even suggested a slight speed-up. Together, these results justify moving forward with a full launch of the variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7be9c529-81d4-4366-9b91-458a65f7f770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY OUTPUTS ===\n",
      "srm_chi2_pval         = 0.8524\n",
      "pval_primary          = 0.0002\n",
      "effect_size_primary   = 0.1422\n",
      "pval_guardrail        = 0.5365\n",
      "effect_size_guardrail = -0.0079\n",
      "decision_full_on      = yes\n"
     ]
    }
   ],
   "source": [
    "# 5) SAVE KEY OUTPUTS (as variables)\n",
    "\n",
    "# Already set: srm_chi2_pval, pval_primary, pval_guardrail, effect_size_primary, effect_size_guardrail, decision_full_on\n",
    "print(\"\\n=== SUMMARY OUTPUTS ===\")\n",
    "print(f\"srm_chi2_pval         = {srm_chi2_pval}\")\n",
    "print(f\"pval_primary          = {pval_primary}\")\n",
    "print(f\"effect_size_primary   = {effect_size_primary}\")\n",
    "print(f\"pval_guardrail        = {pval_guardrail}\")\n",
    "print(f\"effect_size_guardrail = {effect_size_guardrail}\")\n",
    "print(f\"decision_full_on      = {decision_full_on}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d640e9ef-be9f-47de-9630-d8594e74314f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
